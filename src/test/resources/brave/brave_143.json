{"query":{"original":"OpenAI supported hardware","show_strict_warning":false,"is_navigational":false,"local_decision":"drop","local_locations_idx":0,"is_news_breaking":false,"spellcheck_off":true,"country":"us","bad_results":false,"should_fallback":false,"postal_code":"","city":"","header_country":"","more_results_available":true,"state":""},"mixed":{"type":"mixed","main":[{"type":"web","index":0,"all":false},{"type":"web","index":1,"all":false},{"type":"news","all":true},{"type":"web","index":2,"all":false},{"type":"web","index":3,"all":false},{"type":"web","index":4,"all":false},{"type":"web","index":5,"all":false},{"type":"web","index":6,"all":false},{"type":"web","index":7,"all":false},{"type":"web","index":8,"all":false},{"type":"web","index":9,"all":false},{"type":"web","index":10,"all":false},{"type":"web","index":11,"all":false},{"type":"web","index":12,"all":false},{"type":"web","index":13,"all":false},{"type":"web","index":14,"all":false},{"type":"web","index":15,"all":false},{"type":"web","index":16,"all":false},{"type":"web","index":17,"all":false},{"type":"web","index":18,"all":false}],"top":[],"side":[]},"news":{"type":"news","results":[{"title":"OpenAI is reportedly in talks with Jony Ive about a hardware project | TechCrunch","url":"https://techcrunch.com/2023/09/27/openai-is-reportedly-in-talks-with-jony-ive-about-a-hardware-project/","is_source_local":false,"is_source_both":false,"description":"The Information reports that OpenAI's Sam Altman has held talks with Jony Ive about designing some sort of hardware -- presumably AI-powered.","family_friendly":true,"meta_url":{"scheme":"https","netloc":"techcrunch.com","hostname":"techcrunch.com","favicon":"https://imgs.search.brave.com/N6VSEVahheQOb7lqfb47dhUOB4XD-6sfQOP94sCe3Oo/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvZGI5Njk0Yzlk/YWM3ZWMwZjg1MTM1/NmIyMWEyNzBjZDZj/ZDQyNmFlNGU0NDRi/MDgyYjQwOGU0Y2Qy/ZWMwNWQ2ZC90ZWNo/Y3J1bmNoLmNvbS8","path":"‚Ä∫ 2023  ‚Ä∫ 09  ‚Ä∫ 27  ‚Ä∫ openai-is-reportedly-in-talks-with-jony-ive-about-a-hardware-project"},"breaking":false,"thumbnail":{"src":"https://imgs.search.brave.com/_JHS3mhJmXnpUzwPA6d4ADPDoSfmCFeqWPwDGwcSDfk/rs:fit:200:200:1/g:ce/aHR0cHM6Ly90ZWNo/Y3J1bmNoLmNvbS93/cC1jb250ZW50L3Vw/bG9hZHMvMjAyMy8w/NC9HZXR0eUltYWdl/cy0xMTc4ODEwNjk5/LmpwZz93PTEwMjQ"},"age":"2 days ago"},{"title":"Ex-Apple designer Ive, OpenAI's Altman discuss AI hardware -The Information | Reuters","url":"https://www.reuters.com/technology/ex-apple-designer-ive-openais-altman-discuss-ai-hardware-the-information-2023-09-27/","is_source_local":false,"is_source_both":false,"description":"Apple's former design chief, Jony Ive, and OpenAI CEO Sam Altman have been discussing building a new artificial intelligence (AI) hardware device, The Information reported on Tuesday, citing two people familiar with the matter.","family_friendly":true,"meta_url":{"scheme":"https","netloc":"reuters.com","hostname":"www.reuters.com","favicon":"https://imgs.search.brave.com/Ae938I6f5q1DFa90iCd8oQJYp9J-9-3jd1UMrGzFV7Y/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvMzE0MWM3N2Ji/ZjQ3ZDhmYzI3NjMz/ODNjYTRiMGI4MjM4/OTExMzRkM2E1ODI4/MjI4YzA0ZWQ0OTRk/YWY5YTQwMy93d3cu/cmV1dGVycy5jb20v","path":"‚Ä∫ technology  ‚Ä∫ ex-apple-designer-ive-openais-altman-discuss-ai-hardware-the-information-2023-09-27"},"breaking":false,"thumbnail":{"src":"https://imgs.search.brave.com/f0Gj_okbSNGvEDPNyw-h2C0fP-FkG0HPt5Hvvply4qc/rs:fit:200:200:1/g:ce/aHR0cHM6Ly93d3cu/cmV1dGVycy5jb20v/cmVzaXplci9MTnB0/ckhKUUFOYThReWU4/X0REbWI1SER4X0k9/LzEyMDB4NjI4L3Nt/YXJ0L2ZpbHRlcnM6/cXVhbGl0eSg4MCkv/Y2xvdWRmcm9udC11/cy1lYXN0LTIuaW1h/Z2VzLmFyY3B1Ymxp/c2hpbmcuY29tL3Jl/dXRlcnMvUE5MQUpZ/QVU3UklURE5MWDZR/UVVXQktaTFUuanBn"},"age":"2 days ago"},{"title":"Designer Jony Ive and OpenAI‚Äôs Sam Altman Discuss AI Hardware Project","url":"https://www.theinformation.com/articles/designer-jony-ive-and-open-ais-sam-altman-discuss-ai-hardware-project","is_source_local":false,"is_source_both":false,"description":"Jony Ive, therenowned designer of the iPhone, and OpenAI CEO Sam Altman have been discussing building a new AI hardware device, according to two people familiar with the conversations. SoftBank CEO and investor Masayoshi Son has talked to both about the idea, according to one of these people, ...","family_friendly":true,"meta_url":{"scheme":"https","netloc":"theinformation.com","hostname":"www.theinformation.com","favicon":"https://imgs.search.brave.com/Wi-XFya59CTFA07Mw6Dg-rje5TNIx8hzMUzDu1iWC8M/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvY2FhZDY5ODg1/NmI4NGE1NmUwN2M5/MzFjMjI2NjNkNTU0/YTMyMDNhM2FlNTI1/YWRiMjAwNjMxMjY4/OTVhYTUwNC93d3cu/dGhlaW5mb3JtYXRp/b24uY29tLw","path":"‚Ä∫ articles  ‚Ä∫ designer-jony-ive-and-open-ais-sam-altman-discuss-ai-hardware-project"},"breaking":false,"thumbnail":{"src":"https://imgs.search.brave.com/kE3OTKVpkocJwXRZuvttsCZ3ADUX0FhNFFeQmVcvnHg/rs:fit:200:200:1/g:ce/aHR0cHM6Ly90aWku/aW1naXgubmV0L3By/b2R1Y3Rpb24vYXJ0/aWNsZXMvMTEzNDIv/ZDZiMWQ4ZWUtNjkz/Ny00ZTBjLWEyNjYt/MTNlNDM3OTY0YmIz/LnBuZz9mbT1qcGcm/YXV0bz1jb21wcmVz/cyZ3PTEyMDAmZnJh/bWU9MA"},"age":"2 days ago"}],"mutated_by_goggles":false},"type":"search","web":{"type":"search","results":[{"title":"OpenAI - Wikipedia","url":"https://en.wikipedia.org/wiki/OpenAI","is_source_local":false,"is_source_both":false,"description":"Vishal Sikka, former CEO of Infosys, stated that an &quot;openness&quot; where the endeavor would &quot;produce results generally in the greater interest of humanity&quot; was a fundamental requirement for his <strong>support</strong>, and that <strong>OpenAI</strong> &quot;aligns very nicely with our long-held values&quot; and their &quot;endeavor to do purposeful ...","profile":{"name":"Wikipedia","url":"https://en.wikipedia.org/wiki/OpenAI","long_name":"en.wikipedia.org","img":"https://imgs.search.brave.com/0kxnVOiqv-faZvOJc7zpym4Zin1CTs1f1svfNZSzmfU/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvNjQwNGZhZWY0/ZTQ1YWUzYzQ3MDUw/MmMzMGY3NTQ0ZjNj/NDUwMDk5ZTI3MWRk/NWYyNTM4N2UwOTE0/NTI3ZDQzNy9lbi53/aWtpcGVkaWEub3Jn/Lw"},"language":"en","family_friendly":true,"type":"search_result","subtype":"generic","meta_url":{"scheme":"https","netloc":"en.wikipedia.org","hostname":"en.wikipedia.org","favicon":"https://imgs.search.brave.com/0kxnVOiqv-faZvOJc7zpym4Zin1CTs1f1svfNZSzmfU/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvNjQwNGZhZWY0/ZTQ1YWUzYzQ3MDUw/MmMzMGY3NTQ0ZjNj/NDUwMDk5ZTI3MWRk/NWYyNTM4N2UwOTE0/NTI3ZDQzNy9lbi53/aWtpcGVkaWEub3Jn/Lw","path":"‚Ä∫ wiki  ‚Ä∫ OpenAI"},"thumbnail":{"src":"https://imgs.search.brave.com/mRgXfjSLWf7bWyHQJmE--dBq9vOSjGnWvSgN1oXTKOU/rs:fit:200:200:1/g:ce/aHR0cHM6Ly91cGxv/YWQud2lraW1lZGlh/Lm9yZy93aWtpcGVk/aWEvY29tbW9ucy8z/LzMzL1Bpb25lZXJf/QnVpbGRpbmclMkNf/U2FuX0ZyYW5jaXNj/b18lMjgyMDE5JTI5/Xy0xLmpwZw","original":"https://upload.wikimedia.org/wikipedia/commons/3/33/Pioneer_Building%2C_San_Francisco_%282019%29_-1.jpg","logo":false},"age":"16 hours ago","extra_snippets":["OpenAI states that AI \"should be an extension of individual human wills and, in the spirit of liberty, as broadly and evenly distributed as possible.\" Co-chair Sam Altman expects the decades-long project to surpass human intelligence. Vishal Sikka, former CEO of Infosys, stated that an \"openness\" where the endeavor would \"produce results generally in the greater interest of humanity\" was a fundamental requirement for his support, and that OpenAI \"aligns very nicely with our long-held values\" and their \"endeavor to do purposeful work\".","In May 2023, OpenAI launched a user interface for ChatGPT for the App Store and later in July 2023 for the Play store. The app supports chat history syncing and voice input (using Whisper, OpenAI's speech recognition model).","OpenAI announced that they are going to discontinue support for Codex API starting from March 23, 2023. Released in 2022, Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multi-task model that can perform multilingual speech recognition as well as speech translation and language identification. On March 14, 2023, OpenAI announced the release of Generative Pre-trained Transformer 4 (GPT-4), capable of accepting text or image inputs.","OpenAI is an American artificial intelligence (AI) research laboratory consisting of the non-profit OpenAI, Inc. and its for-profit subsidiary corporation OpenAI, L.P. registered in Delaware. OpenAI conducts research on artificial intelligence with the declared intention of developing \"safe and beneficial\" artificial general intelligence, which it defines as \"highly autonomous systems that outperform humans at most economically valuable work\"."]},{"title":"How Nvidia‚Äôs CUDA Monopoly In Machine Learning Is Breaking - ...","url":"https://www.semianalysis.com/p/nvidiaopenaitritonpytorch","is_source_local":false,"is_source_both":false,"description":"We didn&#x27;t want to build a compiler that only <strong>supported</strong> GPUs. We wanted something that could scale to <strong>support</strong> a wide variety of <strong>hardware</strong> back ends, and having a C++ as well as [<strong>OpenAI</strong>] Triton forces that generality.","profile":{"name":"Semianalysis","url":"https://www.semianalysis.com/p/nvidiaopenaitritonpytorch","long_name":"semianalysis.com","img":"https://imgs.search.brave.com/OXAWKaljwz-sruzjtrvksuXkOQWsnYxk4sOk044d0xY/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvM2Y1NThmNmIy/NzlhODE0ZjkxMjM1/ZDIzZTE2YTkxODE0/MmE2NjBmNDcyNDRh/YWNjMzU4NzgwNDFk/ZGNhYzMxMy93d3cu/c2VtaWFuYWx5c2lz/LmNvbS8"},"language":"en","family_friendly":true,"type":"search_result","subtype":"article","meta_url":{"scheme":"https","netloc":"semianalysis.com","hostname":"www.semianalysis.com","favicon":"https://imgs.search.brave.com/OXAWKaljwz-sruzjtrvksuXkOQWsnYxk4sOk044d0xY/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvM2Y1NThmNmIy/NzlhODE0ZjkxMjM1/ZDIzZTE2YTkxODE0/MmE2NjBmNDcyNDRh/YWNjMzU4NzgwNDFk/ZGNhYzMxMy93d3cu/c2VtaWFuYWx5c2lz/LmNvbS8","path":"‚Ä∫ p  ‚Ä∫ nvidiaopenaitritonpytorch"},"thumbnail":{"src":"https://imgs.search.brave.com/upic_dQzPNGjIUZI9gFCQYf6sy-550TjQP6yaCI29j4/rs:fit:200:200:1/g:ce/aHR0cHM6Ly9zdWJz/dGFjay1wb3N0LW1l/ZGlhLnMzLmFtYXpv/bmF3cy5jb20vcHVi/bGljL2ltYWdlcy81/MWFiN2M0Ny0wOGRi/LTQyYzktODAwMS1l/MTk1MTg0ZDJhMTdf/OTM2eDQ3NC5qcGVn","original":"https://substack-post-media.s3.amazonaws.com/public/images/51ab7c47-08db-42c9-8001-e195184d2a17_936x474.jpeg","logo":false},"age":"January 16, 2023","article":{"author":[{"type":"person","name":"Dylan Patel","url":"https://substack.com/@semianalysis","thumbnail":{"src":"https://imgs.search.brave.com/hBC0RHjc6lV-ExkeSqkV_VLnDDkoXKmzv4EaKoVLX1Y/rs:fit:200:200:1/g:ce/aHR0cHM6Ly9zdWJz/dGFja2Nkbi5jb20v/aW1hZ2UvZmV0Y2gv/Zl9hdXRvLHFfYXV0/bzpnb29kLGZsX3By/b2dyZXNzaXZlOnN0/ZWVwL2h0dHBzJTNB/JTJGJTJGc3Vic3Rh/Y2stcG9zdC1tZWRp/YS5zMy5hbWF6b25h/d3MuY29tJTJGcHVi/bGljJTJGaW1hZ2Vz/JTJGYWRjZjlkNTMt/NzY5ZS00ZDllLTg5/ODItMzBjM2RjODQ4/OGRjXzUwMXg1Mjcu/cG5n","original":"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fadcf9d53-769e-4d9e-8982-30c3dc8488dc_501x527.png"}}],"date":"Jan 16, 2023","publisher":{"type":"organization","name":"SemiAnalysis","url":"https://www.semianalysis.com","thumbnail":{"src":"https://imgs.search.brave.com/wbfwxAUMXlzV9qEoRbhMy77rT3annuC-8nWH7hlV9Yc/rs:fit:200:200:1/g:ce/aHR0cHM6Ly9zdWJz/dGFja2Nkbi5jb20v/aW1hZ2UvZmV0Y2gv/Zl9hdXRvLHFfYXV0/bzpnb29kLGZsX3By/b2dyZXNzaXZlOnN0/ZWVwL2h0dHBzJTNB/JTJGJTJGYnVja2V0/ZWVyLWUwNWJiYzg0/LWJhYTMtNDM3ZS05/NTE4LWFkYjMyYmU3/Nzk4NC5zMy5hbWF6/b25hd3MuY29tJTJG/cHVibGljJTJGaW1h/Z2VzJTJGMDE1MDc3/NmMtOWJmMi00YmVh/LWE5YzItNDFiMjRi/N2EwZjE1XzEyODB4/MTI4MC5wbmc","original":"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F0150776c-9bf2-4bea-a9c2-41b24b7a0f15_1280x1280.png"}},"isAccessibleForFree":false},"extra_snippets":["OpenAI Triton only officially supports Nvidia GPUs today, but that is changing in the near future. Multiple other hardware vendors will be supported in the future, and this open-source project is gaining incredible steam. The ability for other hardware accelerators to integrate directly into the LLVM IR that is part of Triton dramatically reduces the time to build an AI compiler stack for a new piece of hardware.","The backend code generation portion leverages OpenAI Triton for GPUs and outputs PTX code. For CPUs, an Intel compiler generates C++ (will work on non-Intel CPUs too). More hardware will be supported going forward, but the key is that Inductor dramatically reduces the amount of work a compiler team must do when making a compiler for their AI hardware accelerator.","The rest of this report will point out the specific hardware accelerator that has a huge win at Microsoft, as well as multiple companies‚Äô hardware that is quickly being integrated into the PyTorch 2.0/OpenAI Trion software stack. Furthermore, it will share the opposing view as a defense of Nvidia‚Äôs moat/strength in the AI training market. SemiAnalysis is an ad-free, reader-supported publication."]},{"title":"GitHub - go-skynet/LocalAI: :robot: The free, Open Source OpenAI ...","url":"https://github.com/go-skynet/LocalAI","is_source_local":false,"is_source_both":false,"description":"LocalAI is a drop-in replacement REST API that&#x27;s compatible with <strong>OpenAI</strong> API specifications for local inferencing. It allows you to run LLMs (and not only) locally or on-prem with consumer grade <strong>hardware</strong>, <strong>supporting</strong> multiple model families that are compatible with the ggml format, pytorch and more.","profile":{"name":"GitHub","url":"https://github.com/go-skynet/LocalAI","long_name":"github.com","img":"https://imgs.search.brave.com/v8685zI4XInM0zxlNI2s7oE_2Sb-EL7lAy81WXbkQD8/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvYWQyNWM1NjA5/ZjZmZjNlYzI2MDNk/N2VkNmJhYjE2MzZl/MDY5ZTMxMDUzZmY1/NmU3NWIzNWVmMjk0/NTBjMjJjZi9naXRo/dWIuY29tLw"},"language":"en","family_friendly":true,"type":"search_result","subtype":"software","meta_url":{"scheme":"https","netloc":"github.com","hostname":"github.com","favicon":"https://imgs.search.brave.com/v8685zI4XInM0zxlNI2s7oE_2Sb-EL7lAy81WXbkQD8/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvYWQyNWM1NjA5/ZjZmZjNlYzI2MDNk/N2VkNmJhYjE2MzZl/MDY5ZTMxMDUzZmY1/NmU3NWIzNWVmMjk0/NTBjMjJjZi9naXRo/dWIuY29tLw","path":"‚Ä∫ go-skynet  ‚Ä∫ LocalAI"},"thumbnail":{"src":"https://imgs.search.brave.com/Y1baMAJMez8JtRa-yXio3NTKCCCYefTPrOPgSkSN7mE/rs:fit:200:200:1/g:ce/aHR0cHM6Ly9vcGVu/Z3JhcGguZ2l0aHVi/YXNzZXRzLmNvbS8w/YjE1OTY3N2JjOGE2/YzQyM2VmMmIzYzZl/YWQzNzRlOTRlNWUx/OWI2NTk0NzJmNTY5/MjllNDdiMWY0NjNl/ZGQyL2dvLXNreW5l/dC9Mb2NhbEFJ","original":"https://opengraph.githubassets.com/0b159677bc8a6c423ef2b3c6ead374e94e5e19b659472f56929e47b1f463edd2/go-skynet/LocalAI","logo":false},"software":{"name":"LocalAI","author":"go-skynet","is_npm":false,"is_pypi":false,"stars":11500,"forks":1000,"programmingLanguage":"Go 58.9% | Python 34.5% | Makefile 4.9% | Dockerfile 1.4%"},"extra_snippets":["It allows you to run LLMs (and not only) locally or on-prem with consumer grade hardware, supporting multiple model families that are compatible with the ggml format, pytorch and more. Does not require GPU. ... Local, OpenAI drop-in alternative REST API. You own your data.","A huge thank you to our generous sponsors who support this project: And a huge shout-out to individuals sponsoring the project by donating hardware or backing the project. ... LocalAI is a community-driven project created by Ettore Di Giacinto. ... LocalAI couldn't have been built without the help of great software already available from the community. Thank you! ... ü§ñ The free, Open Source OpenAI alternative.",":robot: The free, Open Source OpenAI alternative. Self-hosted, community-driven and local-first. Drop-in replacement for OpenAI running on consumer-grade hardware. No GPU required. Runs ggml, gguf, GPTQ, onnx, TF compatible models: llama, llama2, rwkv, whisper, vicuna, koala, cerebras, falcon, dolly, starcoder, and many others - GitHub - go-skynet/LocalAI: :robot: The free, Open Source OpenAI alternative."]},{"title":"OpenAI Presents GPT-3, a 175 Billion Parameters Language Model ...","url":"https://developer.nvidia.com/blog/openai-presents-gpt-3-a-175-billion-parameters-language-model/","is_source_local":false,"is_source_both":false,"description":"<strong>OpenAI</strong> researchers recently released a paper describing the development of GPT-3, a state-of-the-art language model made up of 175 billion parameters.","profile":{"name":"Nvidia","url":"https://developer.nvidia.com/blog/openai-presents-gpt-3-a-175-billion-parameters-language-model/","long_name":"developer.nvidia.com","img":"https://imgs.search.brave.com/VY0m57gEt-aHSC-AtOkAhM5klKctq4igpcQASnGa0rE/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvNjYyY2MyYWEy/ZTg0MmIyMDE5Yzlh/ZDgwZmRmMjQwNGE0/ZGNiZjBmM2I0OWY1/YTUyYTA5OTRlYzUx/MWFiZjg1MC9kZXZl/bG9wZXIubnZpZGlh/LmNvbS8"},"language":"en","family_friendly":true,"type":"search_result","subtype":"generic","meta_url":{"scheme":"https","netloc":"developer.nvidia.com","hostname":"developer.nvidia.com","favicon":"https://imgs.search.brave.com/VY0m57gEt-aHSC-AtOkAhM5klKctq4igpcQASnGa0rE/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvNjYyY2MyYWEy/ZTg0MmIyMDE5Yzlh/ZDgwZmRmMjQwNGE0/ZGNiZjBmM2I0OWY1/YTUyYTA5OTRlYzUx/MWFiZjg1MC9kZXZl/bG9wZXIubnZpZGlh/LmNvbS8","path":"  ‚Ä∫ nvidia technical blog  ‚Ä∫ conversational ai / nlp  ‚Ä∫ openai presents gpt-3, a 175 billion parameters language model"},"thumbnail":{"src":"https://imgs.search.brave.com/3y-BrvGUTmcQcxzpZZAvEQMz8UqAavLNxWWdqewFzfE/rs:fit:200:200:1/g:ce/aHR0cHM6Ly9kZXZl/bG9wZXItYmxvZ3Mu/bnZpZGlhLmNvbS93/cC1jb250ZW50L3Vw/bG9hZHMvMjAyMC8w/Ny9PcGVuQUktR1BU/LTMtZmVhdHVyZWQt/aW1hZ2UucG5n","original":"https://developer-blogs.nvidia.com/wp-content/uploads/2020/07/OpenAI-GPT-3-featured-image.png","logo":false}},{"title":"AI and Compute - OpenAI","url":"https://openai.com/blog/ai-and-compute/","is_source_local":false,"is_source_both":false,"description":"We‚Äôre releasing an analysis showing that since 2012, the amount of compute used in the largest AI training runs has been increasing exponentially with a 3.4-month doubling time (by comparison, Moore‚Äôs Law had a 2-year doubling period)[^footnote-correction]. Since 2012, this metric has grown ...","profile":{"name":"Openai","url":"https://openai.com/blog/ai-and-compute/","long_name":"openai.com","img":"https://imgs.search.brave.com/WPoK3r5Z8uGwQwVPN8tiC66KBX5afaybeq-g0pGscwk/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvNWE0ODk4ZGY3/Mzk1Y2EwMjAxZjJk/YmEzZWM1MzcyNTZm/MTI0YWEyOWQ3NjVk/MDgxNTMwMGQxNWMx/ZWVmZWMzZC9vcGVu/YWkuY29tLw"},"language":"en","family_friendly":true,"type":"search_result","subtype":"generic","meta_url":{"scheme":"https","netloc":"openai.com","hostname":"openai.com","favicon":"https://imgs.search.brave.com/WPoK3r5Z8uGwQwVPN8tiC66KBX5afaybeq-g0pGscwk/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvNWE0ODk4ZGY3/Mzk1Y2EwMjAxZjJk/YmEzZWM1MzcyNTZm/MTI0YWEyOWQ3NjVk/MDgxNTMwMGQxNWMx/ZWVmZWMzZC9vcGVu/YWkuY29tLw","path":"‚Ä∫ blog  ‚Ä∫ ai-and-compute"},"thumbnail":{"src":"https://imgs.search.brave.com/_BnxgW8Fs6rOjGIU_QG5DCxkR2ql7rf3OsqmMzUd2oU/rs:fit:200:200:1/g:ce/aHR0cHM6Ly9pbWFn/ZXMub3BlbmFpLmNv/bS9ibG9iL2VlODY3/NmQ4LTg2MTQtNDE1/MS04N2E0LTU4YWMx/NzkyZWJiOS9haS1h/bmQtY29tcHV0ZS5w/bmc_dHJpbT0wJTJD/MCUyQzY5MSUyQzAm/d2lkdGg9MTAwMCZx/dWFsaXR5PTgw","original":"https://images.openai.com/blob/ee8676d8-8614-4151-87a4-58ac1792ebb9/ai-and-compute.png?trim=0%2C0%2C691%2C0&width=1000&quality=80","logo":false},"extra_snippets":["We‚Äôre releasing an analysis showing that since 2012, the amount of compute used in the largest AI training runs has been increasing exponentially with a 3.4-month doubling time (by comparison, Moore‚Äôs Law had a 2-year doubling period)[^footnote-correction]. Since 2012, this metric has grown by more than 300,000x (a 2-year doubling period would yield only a 7x increase)."]},{"title":"The Hardware in Microsoft‚Äôs OpenAI Supercomputer Is Insane | ...","url":"https://www.engineering.com/story/the-hardware-in-microsofts-openai-supercomputer-is-insane","is_source_local":false,"is_source_both":false,"description":"The benefit to Elon Musk‚Äôs organization is not yet clear.","profile":{"name":"Engineering","url":"https://www.engineering.com/story/the-hardware-in-microsofts-openai-supercomputer-is-insane","long_name":"engineering.com","img":"https://imgs.search.brave.com/lcsk5IE8BD3n0P5tZPSqjQY45Ynye1fnCyMYkwU2Sqk/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvYjY3YmY5NDI1/NzRiMDExNTFhNDlk/ZmZlZDBiYmQ0NmFi/OWEwMDYwN2Y1Y2Qy/ZTFmOTFjZDVmNGJh/NDQyMmU0Zi93d3cu/ZW5naW5lZXJpbmcu/Y29tLw"},"language":"en","family_friendly":true,"type":"search_result","subtype":"generic","meta_url":{"scheme":"https","netloc":"engineering.com","hostname":"www.engineering.com","favicon":"https://imgs.search.brave.com/lcsk5IE8BD3n0P5tZPSqjQY45Ynye1fnCyMYkwU2Sqk/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvYjY3YmY5NDI1/NzRiMDExNTFhNDlk/ZmZlZDBiYmQ0NmFi/OWEwMDYwN2Y1Y2Qy/ZTFmOTFjZDVmNGJh/NDQyMmU0Zi93d3cu/ZW5naW5lZXJpbmcu/Y29tLw","path":"‚Ä∫ story  ‚Ä∫ the-hardware-in-microsofts-openai-supercomputer-is-insane"},"thumbnail":{"src":"https://imgs.search.brave.com/S8-kv5_jjtgxe95Vfj1M_m6fjQujeet9nxDA4Pj-uQU/rs:fit:200:200:1/g:ce/aHR0cHM6Ly93d3cu/ZW5naW5lZXJpbmcu/Y29tL3BvcnRhbHMv/MC9CbG9nRmlsZXMv/MjZfaW1hMS5wbmc","original":"https://www.engineering.com/portals/0/BlogFiles/26_ima1.png","logo":false}},{"title":"OpenAI Whisper Audio Transcription Benchmarked on 18 GPUs: Up to ...","url":"https://www.tomshardware.com/news/whisper-audio-transcription-gpus-benchmarked","is_source_local":false,"is_source_both":false,"description":"Besides ChatGPT, Bard, and Bing Chat (aka Sydney), which all run on data center <strong>hardware</strong>, you can run your own local version of Stable Diffusion, Text Generation, and various other tools... like <strong>OpenAI</strong>&#x27;s Whisper. The last one is our subject today, and it can provide substantially faster than ...","profile":{"name":"Tomshardware","url":"https://www.tomshardware.com/news/whisper-audio-transcription-gpus-benchmarked","long_name":"tomshardware.com","img":"https://imgs.search.brave.com/Q7iyQMozfRnTz7L96Rub5BxYf6wIBm7FWaoj4wdotKI/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvODM1NTNmZDRm/OGJmNzdiYzc3ZDQ1/ZGE5ZWYzOWYwNTRl/M2ViMDY1ZWJhMTY2/ZWEwNzQzODliMmM3/ZDc1NWIzZC93d3cu/dG9tc2hhcmR3YXJl/LmNvbS8"},"language":"en","family_friendly":true,"type":"search_result","subtype":"article","meta_url":{"scheme":"https","netloc":"tomshardware.com","hostname":"www.tomshardware.com","favicon":"https://imgs.search.brave.com/Q7iyQMozfRnTz7L96Rub5BxYf6wIBm7FWaoj4wdotKI/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvODM1NTNmZDRm/OGJmNzdiYzc3ZDQ1/ZGE5ZWYzOWYwNTRl/M2ViMDY1ZWJhMTY2/ZWEwNzQzODliMmM3/ZDc1NWIzZC93d3cu/dG9tc2hhcmR3YXJl/LmNvbS8","path":"  ‚Ä∫ news"},"thumbnail":{"src":"https://imgs.search.brave.com/PJ6N0vH7nVSiCPx_ch3y-dY4CD8SV5JlhnFta5Gm8aY/rs:fit:200:200:1/g:ce/aHR0cHM6Ly9jZG4u/bW9zLmNtcy5mdXR1/cmVjZG4ubmV0LzQ5/YU1UOVBFR1d3TlR5/RVRrd0pwemQuanBn","original":"https://cdn.mos.cms.futurecdn.net/49aMT9PEGWwNTyETkwJpzd.jpg","logo":false},"age":"May 11, 2023","article":{"author":[{"type":"person","name":"Jarred Walton","url":"https://www.tomshardware.com/author/jarred-walton","thumbnail":{"src":"https://imgs.search.brave.com/RRH3h1FmSl_msToP29o7erUnsUfT2rt9IYa3ooPkMTA/rs:fit:200:200:1/g:ce/aHR0cHM6Ly9jZG4u/bW9zLmNtcy5mdXR1/cmVjZG4ubmV0Lzh1/RmdTR2NDektkRlRU/UWRxb25DUGkuanBn","original":"https://cdn.mos.cms.futurecdn.net/8uFgSGcCzKdFTTQdqonCPi.jpg"}}],"date":"May 11, 2023","publisher":{"type":"organization","name":"Tom's Hardware","url":"https://www.tomshardware.com","thumbnail":{"src":"https://imgs.search.brave.com/4vRmpuRqzxvx8lA51jz1pJIzROolMtnRSj41ECf5p_M/rs:fit:200:200:1/g:ce/aHR0cHM6Ly92YW5p/bGxhLmZ1dHVyZWNk/bi5uZXQvdG9tc2hh/cmR3YXJlL21lZGlh/L2ltZy9icmFuZF9s/b2dvLnN2Zw.svg","original":"https://vanilla.futurecdn.net/tomshardware/media/img/brand_logo.svg"}}},"extra_snippets":["Besides ChatGPT, Bard, and Bing Chat (aka Sydney), which all run on data center hardware, you can run your own local version of Stable Diffusion, Text Generation, and various other tools... like OpenAI's Whisper. The last one is our subject today, and it can provide substantially faster than real-time transcription of audio via your GPU, with the entire process running locally for free.","Of course there's the OpenAI GitHub (instructions and details below). There's also this Const-Me project, WhisperDesktop, which is a Windows executable written in C++. That uses DirectCompute rather than PyTorch, which means it will run on any DirectX 11 compatible GPU ‚Äî yes, including things like Intel integrated graphics. It also means that it's not using special hardware like Nvidia's Tensor cores or Intel's XMX cores.","It also means that it's not using special hardware like Nvidia's Tensor cores or Intel's XMX cores. Getting WhisperDesktop running proved very easy, assuming you're willing to download and run someone's unsigned executable. (I was, though you can also try to compile the code yourself if you want.) Just grab WhisperDesktop.zip and extract it somewhere. Besides the EXE and DLL, you'll need one or more of the OpenAI models, which you can grab via the links from the application window.","OpenAI only released a large model for Whisper (based on GPT-2) that needs about 10GB of memory, but certainly it could work to improve the accuracy and quality even more while requiring additional VRAM. Our testing of Whisper also shows that coding and optimizations can often trump hardware."]},{"title":"OpenAI Impact Analysis: Microsoft, Google And Nvidia (NASDAQ:MSFT) ...","url":"https://seekingalpha.com/article/4562442-openai-impact-analysis-microsoft-google-and-nvidia","is_source_local":false,"is_source_both":false,"description":"The supercomputer developed for <strong>OpenAI</strong> is a single system with more than 285,000 CPU cores, 10,000 GPUs and 400 gigabits per second of network connectivity for each GPU server. ... And as the computing performance and cost efficiency of Nvidia‚Äôs <strong>hardware</strong> improves, transformer models like ...","profile":{"name":"Seekingalpha","url":"https://seekingalpha.com/article/4562442-openai-impact-analysis-microsoft-google-and-nvidia","long_name":"seekingalpha.com","img":"https://imgs.search.brave.com/micrGvWMDXYWyJsX3baZdrivYXVH30RjNYE0mYi72t8/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvMGMzN2JkNjhl/ODdiNGFiYzQyOThi/NzM3ZTBhMDExYmM5/ODM2M2U3ZjRkZGJj/MWQxYzkxYzJiYzdk/ZTQ3MjhkMS9zZWVr/aW5nYWxwaGEuY29t/Lw"},"language":"en","family_friendly":true,"type":"search_result","subtype":"article","meta_url":{"scheme":"https","netloc":"seekingalpha.com","hostname":"seekingalpha.com","favicon":"https://imgs.search.brave.com/micrGvWMDXYWyJsX3baZdrivYXVH30RjNYE0mYi72t8/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvMGMzN2JkNjhl/ODdiNGFiYzQyOThi/NzM3ZTBhMDExYmM5/ODM2M2U3ZjRkZGJj/MWQxYzkxYzJiYzdk/ZTQ3MjhkMS9zZWVr/aW5nYWxwaGEuY29t/Lw","path":"  ‚Ä∫ home  ‚Ä∫ stock ideas  ‚Ä∫ quick picks & lists  ‚Ä∫ tech"},"thumbnail":{"src":"https://imgs.search.brave.com/U3NpughqHwAHyFBsCrc4u2MkuxOcdmzpgRY0PVzkQfI/rs:fit:200:200:1/g:ce/aHR0cHM6Ly9zdGF0/aWMuc2Vla2luZ2Fs/cGhhLmNvbS9jZG4v/czMvdXBsb2Fkcy9n/ZXR0eV9pbWFnZXMv/MTM3MzEwMzI1OC9p/bWFnZV8xMzczMTAz/MjU4LmpwZz9pbz1n/ZXR0eS1jLXcxMjgw","original":"https://static.seekingalpha.com/cdn/s3/uploads/getty_images/1373103258/image_1373103258.jpg?io=getty-c-w1280","logo":false},"age":"December 5, 2022","article":{"author":[{"type":"person","name":"Livy Investment Research","url":"https://seekingalpha.com/author/livy-investment-research"}],"date":"Dec 05, 2022","publisher":{"type":"organization","name":"Seeking Alpha","thumbnail":{"src":"https://imgs.search.brave.com/KyAyLrXzIMcWb4fih1whct7f91H-Q3C_LObTOBjG7H0/rs:fit:200:200:1/g:ce/aHR0cHM6Ly9zZWVr/aW5nYWxwaGEuY29t/L3NhbXcvc3RhdGlj/L2ltYWdlcy9QdWJs/aXNoZXJMb2dvLjFh/MGZiMzcyLnBuZw","original":"https://seekingalpha.com/samw/static/images/PublisherLogo.1a0fb372.png"}},"isAccessibleForFree":false},"extra_snippets":["The supercomputer developed for OpenAI is a single system with more than 285,000 CPU cores, 10,000 GPUs and 400 gigabits per second of network connectivity for each GPU server. ... And as the computing performance and cost efficiency of Nvidia‚Äôs hardware improves, transformer models like GPT-3 will also become more refined, putting them a step closer to commercialization.","As for Nvidia, although its valuation has come down significantly while its longer-term growth prospects continue to demonstrate sustainability supported by its ‚Äúmission critical‚Äù role in enabling next-generation innovations like OpenAI‚Äôs language model, the stock continues to trade at a premium to peers with similar growth profiles.","And ChatGPT would be a significant addition to Microsoft‚Äôs portfolio of virtual-environment-centric enterprise software by enabling capitalization of opportunities stemming from ‚Äúdigitization of more than 25 million retail and industrial spaces in need of digital customer support and/or smart contactless check-out cashiers‚Äù over the longer-term. Continued commercialization and integration of OpenAI‚Äôs technologies would effectively enable greater returns on investment for Microsoft.","OpenAI's chatbot, ChatGPT, which was released to the broader public for testing and feedback last week. Read more on its impact on major tech stocks."]},{"title":"r/OpenAI on Reddit: What hardware do you host your OpenAI program on?","url":"https://www.reddit.com/r/OpenAI/comments/11o6det/what_hardware_do_you_host_your_openai_program_on/","is_source_local":false,"is_source_both":false,"description":"I am just wondering what <strong>hardware</strong> people are using to host their <strong>OpenAI</strong> programs.","profile":{"name":"Reddit","url":"https://www.reddit.com/r/OpenAI/comments/11o6det/what_hardware_do_you_host_your_openai_program_on/","long_name":"reddit.com","img":"https://imgs.search.brave.com/mAZYEK9Wi13WLDUge7XZ8YuDTwm6DP6gBjvz1GdYZVY/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvN2ZiNTU0M2Nj/MTFhZjRiYWViZDlk/MjJiMjBjMzFjMDRk/Y2IzYWI0MGI0MjVk/OGY5NzQzOGQ5NzQ5/NWJhMWI0NC93d3cu/cmVkZGl0LmNvbS8"},"language":"en","family_friendly":true,"type":"search_result","subtype":"article","meta_url":{"scheme":"https","netloc":"reddit.com","hostname":"www.reddit.com","favicon":"https://imgs.search.brave.com/mAZYEK9Wi13WLDUge7XZ8YuDTwm6DP6gBjvz1GdYZVY/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvN2ZiNTU0M2Nj/MTFhZjRiYWViZDlk/MjJiMjBjMzFjMDRk/Y2IzYWI0MGI0MjVk/OGY5NzQzOGQ5NzQ5/NWJhMWI0NC93d3cu/cmVkZGl0LmNvbS8","path":"  ‚Ä∫ r/openai  ‚Ä∫ what hardware do you host your openai program on?"},"thumbnail":{"src":"https://imgs.search.brave.com/0Uws9Xair0pH-I24v67ryQNS-DH6a6I5j6ziUvKsgfg/rs:fit:200:200:1/g:ce/aHR0cHM6Ly93d3cu/cmVkZGl0c3RhdGlj/LmNvbS9pY29uLnBu/Zw","original":"https://www.redditstatic.com/icon.png","logo":false},"age":"March 11, 2023","article":{"author":[{"type":"person","name":"Eldereon","url":"https://www.reddit.com/user/Eldereon/"}],"date":"Mar 11, 2023","publisher":{"type":"organization","name":"Reddit","thumbnail":{"src":"https://imgs.search.brave.com/axK82n8DGOv8Y6FUUFSZTA0xm5zEmDGfzL9oR3h-T1A/rs:fit:200:200:1/g:ce/aHR0cHM6Ly93d3cu/cmVkZGl0c3RhdGlj/LmNvbS9td2ViMngv/ZmF2aWNvbi82NHg2/NC5wbmc","original":"https://www.redditstatic.com/mweb2x/favicon/64x64.png"}}},"extra_snippets":["Hardware is client hardware itself direct communication with the API. if you are interested in another improved ChatGPT client check it out here www.chatworm.com ... Release openAI api for chatgpt become the last drop and I bought a NAS. Now I am using synology ds720+ for hosting my chatGPT bot and for backups of course.","Posted by u/Eldereon - 5 votes and 19 comments"]},{"title":"r/MachineLearning on Reddit: [D] What would it take to run OpenAI's ...","url":"https://www.reddit.com/r/MachineLearning/comments/gzb5uv/d_what_would_it_take_to_run_openais_gpt3_on/","is_source_local":false,"is_source_both":false,"description":"The NLP community has gotten a lot of mileage applying <strong>OpenAI</strong>&#x27;s GPT-2 models to various applications: ... Given the impressive zero-shot/few-shot abilities of GPT-3, what would it take to get it running on affordable <strong>hardware</strong>? What approximations can be made for GPT-3 inference to drastically ...","profile":{"name":"Reddit","url":"https://www.reddit.com/r/MachineLearning/comments/gzb5uv/d_what_would_it_take_to_run_openais_gpt3_on/","long_name":"reddit.com","img":"https://imgs.search.brave.com/mAZYEK9Wi13WLDUge7XZ8YuDTwm6DP6gBjvz1GdYZVY/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvN2ZiNTU0M2Nj/MTFhZjRiYWViZDlk/MjJiMjBjMzFjMDRk/Y2IzYWI0MGI0MjVk/OGY5NzQzOGQ5NzQ5/NWJhMWI0NC93d3cu/cmVkZGl0LmNvbS8"},"language":"en","family_friendly":true,"type":"search_result","subtype":"qa","meta_url":{"scheme":"https","netloc":"reddit.com","hostname":"www.reddit.com","favicon":"https://imgs.search.brave.com/mAZYEK9Wi13WLDUge7XZ8YuDTwm6DP6gBjvz1GdYZVY/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvN2ZiNTU0M2Nj/MTFhZjRiYWViZDlk/MjJiMjBjMzFjMDRk/Y2IzYWI0MGI0MjVk/OGY5NzQzOGQ5NzQ5/NWJhMWI0NC93d3cu/cmVkZGl0LmNvbS8","path":"  ‚Ä∫ r/machinelearning  ‚Ä∫ [d] what would it take to run openai's gpt-3 on commodity hardware?"},"thumbnail":{"src":"https://imgs.search.brave.com/nNstwAlTKfGkyz4eVakYvk84QR8SHnkZFkngarXnnbk/rs:fit:200:200:1/g:ce/aHR0cHM6Ly9zaGFy/ZS5yZWRkLml0L3By/ZXZpZXcvcG9zdC9n/emI1dXY","original":"https://share.redd.it/preview/post/gzb5uv","logo":false},"age":"June 8, 2020","qa":{"question":"[D] What would it take to run OpenAI's GPT-3 on commodity hardware?","answer":{"text":"No one's taken the time to actually run a few simple numbers? Really? Alright, I'll be that guy. For a lower bound estimate, assume that GPT-3 was trained with bfloat16 precision. You can read about that data format and why it's commonly used in this paper . Asssume absolutely no memory overhead other than the raw 16 bits per parameter. We have: 1.75 * 1011 parameters. * 2 for 2 bytes per parameter (16 bits) gives 3.5 * 1011 bytes. To go from bytes to gigs, we multiply by 10-9 3.5 * 1011 * 10-9 = 350 gigs. So your absolute bare minimum lower bound is still a goddamn beefy model. That's ~22 16 gig GPUs worth of memory. I don't deal with the nuts and bolts of giant models, so I'm not sure to what extent the real model size could be bigger, but it's certainly no smaller than 350 gigs at least, seeing that it's a dense model. Kind of cool to run the numbers and get a real world sense of what 175 billion parameters actually means. It's hard drive sized, not RAM sized. The model itself is approaching 'big data' size. I was screwing around with a 250 gig database of a couple billion stars in the milky way from the Gaia satellite... the size of the GPT-3 model is literally 40% larger than my giant astronomy database I was playing with. That's crazy, haha.","author":"adventuringraw","upvoteCount":28}},"extra_snippets":["The NLP community has gotten a lot of mileage applying OpenAI's GPT-2 models to various applications: ... Given the impressive zero-shot/few-shot abilities of GPT-3, what would it take to get it running on affordable hardware? What approximations can be made for GPT-3 inference to drastically lower the compute of the 175B parameter model?","29 votes, 34 comments. The NLP community has gotten a lot of mileage applying OpenAI's GPT-2 models to various applications‚Ä¶","Posted by u/FirstTimeResearcher - 29 votes and 34 comments"]},{"title":"Microsoft details its ChatGPT hardware investments | Network World","url":"https://www.networkworld.com/article/3691289/microsoft-details-its-chatgpt-hardware-investments.html","is_source_local":false,"is_source_both":false,"description":"In addition to sinking billions into <strong>OpenAI</strong>, Microsoft spent hundreds of millions on <strong>hardware</strong>.","profile":{"name":"Networkworld","url":"https://www.networkworld.com/article/3691289/microsoft-details-its-chatgpt-hardware-investments.html","long_name":"networkworld.com","img":"https://imgs.search.brave.com/k-wUOazmhw5a2Uc6WpqQ9jIY09-hLcEVNmPt2ophhC0/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvYjdhMDU4ZDhi/MDA4NzUzODg4MGQ1/NjkyMjYzNzFkYjIy/ZTgzN2M0ODJmNzEw/NDg4Njk4NzgzNzQ1/YjY4MjgzYS93d3cu/bmV0d29ya3dvcmxk/LmNvbS8"},"language":"en","family_friendly":true,"type":"search_result","subtype":"article","meta_url":{"scheme":"https","netloc":"networkworld.com","hostname":"www.networkworld.com","favicon":"https://imgs.search.brave.com/k-wUOazmhw5a2Uc6WpqQ9jIY09-hLcEVNmPt2ophhC0/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvYjdhMDU4ZDhi/MDA4NzUzODg4MGQ1/NjkyMjYzNzFkYjIy/ZTgzN2M0ODJmNzEw/NDg4Njk4NzgzNzQ1/YjY4MjgzYS93d3cu/bmV0d29ya3dvcmxk/LmNvbS8","path":"‚Ä∫ article  ‚Ä∫ 3691289  ‚Ä∫ microsoft-details-its-chatgpt-hardware-investments.html"},"thumbnail":{"src":"https://imgs.search.brave.com/cetppIip_0yWOG0ePiMJ0LryLoA6k63HXoVSV6B4GOI/rs:fit:200:200:1/g:ce/aHR0cHM6Ly9pbWFn/ZXMuaWRnZXNnLm5l/dC9pbWFnZXMvaWRn/ZS9pbXBvcnRlZC9p/bWFnZWFwaS8yMDIz/LzAyLzA3LzE1L2No/YXRncHQtYnJvd3Nl/ci1lcndlaXRlcnVu/Z2VuX2NodWFuLWNo/dWFuLTEwMDkzNzI3/NS1sYXJnZS5qcGc_/YXV0bz13ZWJwJnF1/YWxpdHk9ODUsNzA","original":"https://images.idgesg.net/images/idge/imported/imageapi/2023/02/07/15/chatgpt-browser-erweiterungen_chuan-chuan-100937275-large.jpg?auto=webp&quality=85,70","logo":false},"article":{"author":[]},"extra_snippets":["Microsoft investment in ChatGPT doesn‚Äôt just involve money sunk into its maker, OpenAI, but a massive hardware investment in data centers as well which shows that for now, AI solutions are just for the very top tier companies. The partnership between Microsoft and OpenAI dates back to 2019, when Microsoft invested $1 billion in the AI developer.","The partnership between Microsoft and OpenAI dates back to 2019, when Microsoft invested $1 billion in the AI developer. It upped the ante in January with the investment of an additional $10 billion. But ChatGPT has to run on something, and that is Azure hardware in Microsoft data centers.","In a separate blog post, Microsoft talked about how the company started working with OpenAI to help create the supercomputers that are needed for ChatGPT's large language model(and for Microsoft's own Bing Chat. That meant linking up thousands of GPUs together in a new way that even Nvidia hadn‚Äôt thought of, according to Nidhi Chappell, Microsoft head of product for Azure high-performance computing and AI.."]},{"title":"OpenAI","url":"https://openai.com/","is_source_local":false,"is_source_both":false,"description":"Our work to create safe and beneficial AI requires a deep understanding of the potential risks and benefits, as well as careful consideration of the impact ¬∑ We research generative models and how to align them with human values","profile":{"name":"Openai","url":"https://openai.com/","long_name":"openai.com","img":"https://imgs.search.brave.com/WPoK3r5Z8uGwQwVPN8tiC66KBX5afaybeq-g0pGscwk/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvNWE0ODk4ZGY3/Mzk1Y2EwMjAxZjJk/YmEzZWM1MzcyNTZm/MTI0YWEyOWQ3NjVk/MDgxNTMwMGQxNWMx/ZWVmZWMzZC9vcGVu/YWkuY29tLw"},"language":"en","family_friendly":true,"type":"search_result","subtype":"generic","meta_url":{"scheme":"https","netloc":"openai.com","hostname":"openai.com","favicon":"https://imgs.search.brave.com/WPoK3r5Z8uGwQwVPN8tiC66KBX5afaybeq-g0pGscwk/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvNWE0ODk4ZGY3/Mzk1Y2EwMjAxZjJk/YmEzZWM1MzcyNTZm/MTI0YWEyOWQ3NjVk/MDgxNTMwMGQxNWMx/ZWVmZWMzZC9vcGVu/YWkuY29tLw","path":""},"thumbnail":{"src":"https://imgs.search.brave.com/aM306GACoBQ31zN3Vd94fbnqfqLR-Wewb-30pBET1dM/rs:fit:200:200:1/g:ce/aHR0cHM6Ly9pbWFn/ZXMub3BlbmFpLmNv/bS9ibG9iL2ZiNGEy/YmE2LTkxMDktNGM3/Yi1hZjRkLWNhZTUz/MGMzZmE3OC9yZWNy/dWl0bWVudC12aWRl/by1wb3N0ZXIuanBn/P3RyaW09MCUyQzAl/MkMwJTJDMCZ3aWR0/aD0xMDAwJnF1YWxp/dHk9ODA","original":"https://images.openai.com/blob/fb4a2ba6-9109-4c7b-af4d-cae530c3fa78/recruitment-video-poster.jpg?trim=0%2C0%2C0%2C0&width=1000&quality=80","logo":false},"extra_snippets":["Creating safe AGI that benefits all of humanity"]},{"title":"r/selfhosted on Reddit: LocalAI: OpenAI compatible API to run LLM ...","url":"https://www.reddit.com/r/selfhosted/comments/12w4p2f/localai_openai_compatible_api_to_run_llm_models/","is_source_local":false,"is_source_both":false,"description":"With LocalAI, my main goal was to provide an opportunity to run <strong>OpenAI</strong>-similar models locally, on commodity <strong>hardware</strong>, with as little friction as possible. There is a significant fragmentation in the space, with many models forked from ggerganov&#x27;s implementation, and applications built on top ...","profile":{"name":"Reddit","url":"https://www.reddit.com/r/selfhosted/comments/12w4p2f/localai_openai_compatible_api_to_run_llm_models/","long_name":"reddit.com","img":"https://imgs.search.brave.com/mAZYEK9Wi13WLDUge7XZ8YuDTwm6DP6gBjvz1GdYZVY/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvN2ZiNTU0M2Nj/MTFhZjRiYWViZDlk/MjJiMjBjMzFjMDRk/Y2IzYWI0MGI0MjVk/OGY5NzQzOGQ5NzQ5/NWJhMWI0NC93d3cu/cmVkZGl0LmNvbS8"},"language":"en","family_friendly":true,"type":"search_result","subtype":"article","meta_url":{"scheme":"https","netloc":"reddit.com","hostname":"www.reddit.com","favicon":"https://imgs.search.brave.com/mAZYEK9Wi13WLDUge7XZ8YuDTwm6DP6gBjvz1GdYZVY/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvN2ZiNTU0M2Nj/MTFhZjRiYWViZDlk/MjJiMjBjMzFjMDRk/Y2IzYWI0MGI0MjVk/OGY5NzQzOGQ5NzQ5/NWJhMWI0NC93d3cu/cmVkZGl0LmNvbS8","path":"  ‚Ä∫ r/selfhosted  ‚Ä∫ localai: openai compatible api to run llm models locally on consumer grade hardware!"},"thumbnail":{"src":"https://imgs.search.brave.com/5scwUR--wRFVv6r4dxsQU0wdjs6pSjLPGG-OunWmmhs/rs:fit:200:200:1/g:ce/aHR0cHM6Ly9leHRl/cm5hbC1wcmV2aWV3/LnJlZGQuaXQvbG9j/YWxhaS1vcGVuYWkt/Y29tcGF0aWJsZS1h/cGktdG8tcnVuLWxs/bS1tb2RlbHMtbG9j/YWxseS1vbi12MC1h/bWUtOXFmRFlCYk9p/MnpOdlZMY2VJanFU/X3VlWmdhSUxnTFk2/T3dPSlM0LmpwZz9h/dXRvPXdlYnAmcz1h/ZjM0MmZhYTc0MzZk/MThlY2JhN2IyYzdh/ZWFmOGFjNjE5NmQy/MzBh","original":"https://external-preview.redd.it/localai-openai-compatible-api-to-run-llm-models-locally-on-v0-ame-9qfDYBbOi2zNvVLceIjqT_ueZgaILgLY6OwOJS4.jpg?auto=webp&s=af342faa7436d18ecba7b2c7aeaf8ac6196d230a","logo":false},"age":"May 20, 2023","article":{"author":[{"type":"person","name":"mudler_it","url":"https://www.reddit.com/user/mudler_it/"}],"date":"Apr 23, 2023","publisher":{"type":"organization","name":"Reddit","thumbnail":{"src":"https://imgs.search.brave.com/axK82n8DGOv8Y6FUUFSZTA0xm5zEmDGfzL9oR3h-T1A/rs:fit:200:200:1/g:ce/aHR0cHM6Ly93d3cu/cmVkZGl0c3RhdGlj/LmNvbS9td2ViMngv/ZmF2aWNvbi82NHg2/NC5wbmc","original":"https://www.redditstatic.com/mweb2x/favicon/64x64.png"}}},"extra_snippets":["With LocalAI, my main goal was to provide an opportunity to run OpenAI-similar models locally, on commodity hardware, with as little friction as possible. There is a significant fragmentation in the space, with many models forked from ggerganov's implementation, and applications built on top of OpenAI, the OSS alternatives make it challenging to run different models efficiently on local hardware.","There is a significant fragmentation in the space, with many models forked from ggerganov's implementation, and applications built on top of OpenAI, the OSS alternatives make it challenging to run different models efficiently on local hardware. The API model allows to abstract from these complexities, so that anyone can focus on plugging AI to the software, and LocalAI takes care of the interface.","What kind of hardware requirements are expected for this to run? ... Not really, with llama.cpp you can run popular 7b models with 8gb of RAM and 13b models with 16gb of RAM, 30b models with 20gb+ RAM, and so on. That‚Äôs the only hard technical requirements. Other than that, a good CPU helps. But the quality is not in actuality as good as any of the popular OpenAI models, but it‚Äôs fun to play with if you‚Äôre just interested in messing with a completely uncensored language model and exploring the capabilities of it.","Can I use it with a Discord bot, or XXX? Yes! If the client uses OpenAI and supports setting a different base URL to send requests to, you can use the LocalAI endpoint. This allows to use this with every application that was supposed to work with OpenAI, but without changing the application!"]},{"title":"What type of Hardware used in OpenAI ChatGPT Development. | by ...","url":"https://babarjamali.medium.com/what-type-of-hardware-used-in-openai-chatgpt-development-9874ff0b2edd","is_source_local":false,"is_source_both":false,"description":"The #<strong>OpenAI</strong> #ChatGPT used advanced computing specifications in the development of ChatGPT models vary based on the specific model and implementation. They used such type to <strong>hardwares</strong>, such as the‚Ä¶","profile":{"name":"Medium","url":"https://babarjamali.medium.com/what-type-of-hardware-used-in-openai-chatgpt-development-9874ff0b2edd","long_name":"babarjamali.medium.com","img":"https://imgs.search.brave.com/24JC-GwPLzlUS7hi86y9uvIl8Za14-Nj5hkQgjh__X0/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvNjg1NDdmOTJk/YzY2ODkwNzNiZjE3/MWRjYmVkNzAyNDhi/NWVjNzc5YTViMGJk/YjFiMjhjZGEwM2M1/MTU0NGQwNi9iYWJh/cmphbWFsaS5tZWRp/dW0uY29tLw"},"language":"en","family_friendly":true,"type":"search_result","subtype":"article","meta_url":{"scheme":"https","netloc":"babarjamali.medium.com","hostname":"babarjamali.medium.com","favicon":"https://imgs.search.brave.com/24JC-GwPLzlUS7hi86y9uvIl8Za14-Nj5hkQgjh__X0/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvNjg1NDdmOTJk/YzY2ODkwNzNiZjE3/MWRjYmVkNzAyNDhi/NWVjNzc5YTViMGJk/YjFiMjhjZGEwM2M1/MTU0NGQwNi9iYWJh/cmphbWFsaS5tZWRp/dW0uY29tLw","path":"‚Ä∫ what-type-of-hardware-used-in-openai-chatgpt-development-9874ff0b2edd"},"thumbnail":{"src":"https://imgs.search.brave.com/qCYhT70WHuwWb6i8xoJbapgG303uY3Tt4bMaVhyGvj4/rs:fit:200:200:1/g:ce/aHR0cHM6Ly9taXJv/Lm1lZGl1bS5jb20v/djIvcmVzaXplOmZp/dDoxMjAwLzEqNUZF/bDc5RVVkZEMzZHpm/b25LR1hqUS5qcGVn","original":"https://miro.medium.com/v2/resize:fit:1200/1*5FEl79EUddC3dzfonKGXjQ.jpeg","logo":false},"age":"January 27, 2023","article":{"author":[{"type":"person","name":"Babar Ali Jamali","url":"https://babarjamali.medium.com"}],"date":"Jan 27, 2023","publisher":{"type":"organization","name":"Medium","url":"https://babarjamali.medium.com/","thumbnail":{"src":"https://imgs.search.brave.com/sGvESb8uD-aRLW6bFbYA8b3aUBRy0Un-KPZ-ZUvlQyU/rs:fit:200:200:1/g:ce/aHR0cHM6Ly9taXJv/Lm1lZGl1bS5jb20v/djIvcmVzaXplOmZp/dDo2MTYvMSpPTUYz/ZlNxSDh0NHhCSjkt/Nm9aRFp3LnBuZw","original":"https://miro.medium.com/v2/resize:fit:616/1*OMF3fSqH8t4xBJ9-6oZDZw.png"}}},"extra_snippets":["What type of Hardware used in OpenAI ChatGPT Development. Let‚Äôs see hardware configuration.","Let‚Äôs see hardware configuration. The #OpenAI #ChatGPT used advanced computing specifications in the development of ChatGPT models vary based on the specific model and implementation.","The #OpenAI #ChatGPT used advanced computing specifications in the development of ChatGPT models vary based on the specific model and implementation. They used such type to hardwares, such as the original #GPT model, which was trained by #OpenAI, was trained on a dataset of 40 GB of text data using a machine with 8 NVIDIA V100 GPUs and 256 GB of RAM."]},{"title":"Azure OpenAI Service ‚Äì Advanced Language Models | Microsoft Azure","url":"https://azure.microsoft.com/en-us/products/cognitive-services/openai-service/","is_source_local":false,"is_source_both":false,"description":"Azure <strong>OpenAI</strong> Service offers industry-leading coding and language AI models that you can fine-tune to your specific needs for a variety of use cases.","profile":{"name":"Microsoft","url":"https://azure.microsoft.com/en-us/products/cognitive-services/openai-service/","long_name":"azure.microsoft.com","img":"https://imgs.search.brave.com/T5ZA4L4foV0nl4h_OcYAjjrP2FSi-muewe3wh0rxPdQ/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvOWI0MDBkOThm/OGNhMWU0MDYwZGYy/YmRhNjc3YThkYWFj/MDVhZjUxNGRmYjNj/ZWRiMTMwNzRiYTNm/MDc3Zjg5NS9henVy/ZS5taWNyb3NvZnQu/Y29tLw"},"language":"en","family_friendly":true,"type":"search_result","subtype":"generic","meta_url":{"scheme":"https","netloc":"azure.microsoft.com","hostname":"azure.microsoft.com","favicon":"https://imgs.search.brave.com/T5ZA4L4foV0nl4h_OcYAjjrP2FSi-muewe3wh0rxPdQ/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvOWI0MDBkOThm/OGNhMWU0MDYwZGYy/YmRhNjc3YThkYWFj/MDVhZjUxNGRmYjNj/ZWRiMTMwNzRiYTNm/MDc3Zjg5NS9henVy/ZS5taWNyb3NvZnQu/Y29tLw","path":"‚Ä∫ en-us  ‚Ä∫ products  ‚Ä∫ cognitive-services  ‚Ä∫ openai-service"}},{"title":"openai/whisper ‚Äì Run with an API on Replicate","url":"https://replicate.com/openai/whisper","is_source_local":false,"is_source_both":false,"description":"The code and the model weights of Whisper are released under the MIT License. See https://github.com/<strong>openai</strong>/whisper/blob/main/LICENSE for further details.","profile":{"name":"Replicate","url":"https://replicate.com/openai/whisper","long_name":"replicate.com","img":"https://imgs.search.brave.com/pHYcIuh2_mUaDO7TedX_1uEehIP4KeyhPOSEZJbnqaA/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvMzIwMGUyZGVl/N2VkOWRkN2Y0N2Ux/Y2UwZThiNWNkNzll/ZDk1OWU0NzVmZGZi/NTE4NGQ5YjE1ZDc4/ODMxYjk0ZC9yZXBs/aWNhdGUuY29tLw"},"language":"en","family_friendly":true,"type":"search_result","subtype":"generic","meta_url":{"scheme":"https","netloc":"replicate.com","hostname":"replicate.com","favicon":"https://imgs.search.brave.com/pHYcIuh2_mUaDO7TedX_1uEehIP4KeyhPOSEZJbnqaA/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvMzIwMGUyZGVl/N2VkOWRkN2Y0N2Ux/Y2UwZThiNWNkNzll/ZDk1OWU0NzVmZGZi/NTE4NGQ5YjE1ZDc4/ODMxYjk0ZC9yZXBs/aWNhdGUuY29tLw","path":"‚Ä∫ openai  ‚Ä∫ whisper"},"thumbnail":{"src":"https://imgs.search.brave.com/7wBn_ZKtqrfPgMoZ48oHjUWnZ1GzhQalsBLjFkG-1FA/rs:fit:200:200:1/g:ce/aHR0cHM6Ly9vZy5y/ZXBsaWNhdGUuY29t/L2FwaS9tb2RlbHMv/b3BlbmFpL3doaXNw/ZXI","original":"https://og.replicate.com/api/models/openai/whisper","logo":false},"extra_snippets":["Predictions run on Nvidia T4 GPU hardware. Predictions typically complete within 55 seconds. The predict time for this model varies significantly based on the inputs.","Convert speech in audio to text"]},{"title":"OpenAI GPT","url":"https://huggingface.co/docs/transformers/model_doc/openai-gpt","is_source_local":false,"is_source_both":false,"description":"We‚Äôre on a journey to advance and democratize artificial intelligence through open source and open science.","profile":{"name":"Huggingface","url":"https://huggingface.co/docs/transformers/model_doc/openai-gpt","long_name":"huggingface.co","img":"https://imgs.search.brave.com/99Pn_CT-frODt_aY76yeuxx1Xq-z-_qYwAt78oJ0AIg/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvNmYwNDg3ZTZh/YzcxMDgwYmRkOGFm/YTk1MTJiYzQ2NmM5/NWViOGEyNGYyZWEx/NDg4NzQ5NzlhYTA5/NTI0MDA4Yy9odWdn/aW5nZmFjZS5jby8"},"language":"en","family_friendly":true,"type":"search_result","subtype":"generic","meta_url":{"scheme":"https","netloc":"huggingface.co","hostname":"huggingface.co","favicon":"https://imgs.search.brave.com/99Pn_CT-frODt_aY76yeuxx1Xq-z-_qYwAt78oJ0AIg/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvNmYwNDg3ZTZh/YzcxMDgwYmRkOGFm/YTk1MTJiYzQ2NmM5/NWViOGEyNGYyZWEx/NDg4NzQ5NzlhYTA5/NTI0MDA4Yy9odWdn/aW5nZmFjZS5jby8","path":"‚Ä∫ docs  ‚Ä∫ transformers  ‚Ä∫ model_doc  ‚Ä∫ openai-gpt"},"thumbnail":{"src":"https://imgs.search.brave.com/oVcN8wEM35aXqKoqQguCafHzTo6iJeNZpP3aaFH0EnY/rs:fit:200:200:1/g:ce/aHR0cHM6Ly9odWdn/aW5nZmFjZS5jby9m/cm9udC90aHVtYm5h/aWxzL2RvY3MvdHJh/bnNmb3JtZXJzLnBu/Zw","original":"https://huggingface.co/front/thumbnails/docs/transformers.png","logo":false},"extra_snippets":["OpenAIGPTLMHeadModel is supported by this causal language modeling example script, text generation example script and notebook."]},{"title":"Software Engineer, Hardware Health","url":"https://openai.com/careers/software-engineer-hardware-health","is_source_local":false,"is_source_both":false,"description":"<strong>OpenAI</strong>‚Äô<strong>s</strong> <strong>Hardware</strong> Health team oversees all <strong>hardware</strong> health related aspects of our custom-built hyperscale supercomputers. The team is responsible for maximizing the available supercomputing capacity for research and ensuring that our researchers are minimally impacted by <strong>hardware</strong> faults.","profile":{"name":"Openai","url":"https://openai.com/careers/software-engineer-hardware-health","long_name":"openai.com","img":"https://imgs.search.brave.com/WPoK3r5Z8uGwQwVPN8tiC66KBX5afaybeq-g0pGscwk/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvNWE0ODk4ZGY3/Mzk1Y2EwMjAxZjJk/YmEzZWM1MzcyNTZm/MTI0YWEyOWQ3NjVk/MDgxNTMwMGQxNWMx/ZWVmZWMzZC9vcGVu/YWkuY29tLw"},"language":"en","family_friendly":true,"type":"search_result","subtype":"generic","meta_url":{"scheme":"https","netloc":"openai.com","hostname":"openai.com","favicon":"https://imgs.search.brave.com/WPoK3r5Z8uGwQwVPN8tiC66KBX5afaybeq-g0pGscwk/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvNWE0ODk4ZGY3/Mzk1Y2EwMjAxZjJk/YmEzZWM1MzcyNTZm/MTI0YWEyOWQ3NjVk/MDgxNTMwMGQxNWMx/ZWVmZWMzZC9vcGVu/YWkuY29tLw","path":"‚Ä∫ careers  ‚Ä∫ software-engineer-hardware-health"},"thumbnail":{"src":"https://imgs.search.brave.com/pApJvgcAqCd81mtK1PjlJnVrH7FHe9iY23naIbQmqwk/rs:fit:200:200:1/g:ce/aHR0cHM6Ly9vcGVu/YWkuY29tL3NvY2lh/bC9mYWNlYm9vay5w/bmc","original":"https://openai.com/social/facebook.png","logo":false},"extra_snippets":["The hardware health team is being incubated inside OpenAI‚Äôs Scaling team, which operates at the far edge of all available innovations in AI ‚Äî doing the engineering and research required to train large-scale AI models of unprecedented capability. ... As a SWE in Hardware Health, you will work to maintain a sophisticated and comprehensive suite of hardware health tests and collaborate with researchers and our Supercomputing team on root-causing and reliably reproducing newly discovered problems.","Bonus Points if you have expertise and interest in low level details of hardware components, protocols, and associated Linux tooling (PCIe, networking, power management, kernel perf tuning) About OpenAI OpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity.","AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity. At OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology."]},{"title":"r/OpenAI on Reddit: what kind of pc would you need to have a model ...","url":"https://www.reddit.com/r/OpenAI/comments/11fwfjg/what_kind_of_pc_would_you_need_to_have_a_model/","is_source_local":false,"is_source_both":false,"description":"574K subscribers in the <strong>OpenAI</strong> community. <strong>OpenAI</strong> is an AI research and deployment company. <strong>OpenAI</strong>&#x27;s mission is to ensure that artificial general‚Ä¶","profile":{"name":"Reddit","url":"https://www.reddit.com/r/OpenAI/comments/11fwfjg/what_kind_of_pc_would_you_need_to_have_a_model/","long_name":"reddit.com","img":"https://imgs.search.brave.com/mAZYEK9Wi13WLDUge7XZ8YuDTwm6DP6gBjvz1GdYZVY/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvN2ZiNTU0M2Nj/MTFhZjRiYWViZDlk/MjJiMjBjMzFjMDRk/Y2IzYWI0MGI0MjVk/OGY5NzQzOGQ5NzQ5/NWJhMWI0NC93d3cu/cmVkZGl0LmNvbS8"},"language":"en","family_friendly":true,"type":"search_result","subtype":"qa","meta_url":{"scheme":"https","netloc":"reddit.com","hostname":"www.reddit.com","favicon":"https://imgs.search.brave.com/mAZYEK9Wi13WLDUge7XZ8YuDTwm6DP6gBjvz1GdYZVY/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvN2ZiNTU0M2Nj/MTFhZjRiYWViZDlk/MjJiMjBjMzFjMDRk/Y2IzYWI0MGI0MjVk/OGY5NzQzOGQ5NzQ5/NWJhMWI0NC93d3cu/cmVkZGl0LmNvbS8","path":"  ‚Ä∫ r/openai  ‚Ä∫ what kind of pc would you need to have a model like chat gpt run just on your machine?"},"thumbnail":{"src":"https://imgs.search.brave.com/SzsrsR3PUBKzFkbCa32fDd8kY0neA_skKDjUDExmMeE/rs:fit:200:200:1/g:ce/aHR0cHM6Ly9zaGFy/ZS5yZWRkLml0L3By/ZXZpZXcvcG9zdC8x/MWZ3Zmpn","original":"https://share.redd.it/preview/post/11fwfjg","logo":false},"age":"March 2, 2023","qa":{"question":"what kind of pc would you need to have a model like chat gpt run just on your machine?","answer":{"text":"From a GPT-NeoX deployment guide: It was still possible to deploy GPT-J on consumer hardware, even if it was very expensive. For example, you could deploy it on a very good CPU (even if the result was painfully slow) or on an advanced gaming GPU like the NVIDIA RTX 3090. But GPT-NeoX 20B is so big that it's not possible anymore. Basically GPT-NeoX requires at least 42GB of VRAM and 40 GB of disk space (and yes we're talking about the slim fp16 version here). Few GPUs match these requirements. The main ones are the NVIDIA A100, A40, and RTX A6000. NeoX is 20 Billion parameters, whereas ChatGPT is 175 Billion parameters and requires much more memory. Amazon has an A100 40gb card for $8,500. From what I recall, to do any training on NeoX, you need 10x as much VRAM. This is why hosted services are going to be the only option for most use cases. Then each user shares a part of the costs of operation. This may change in the future, several groups are working on diffusion based Language models that hold promise to reduce compute costs like Stable Diffusion has.","author":"Sailor_in_exile","upvoteCount":8}},"extra_snippets":["Motherboard: ASUS TUF GAMING B550-PLUS for a solid and reliable foundation for the system, which supports the AM4 socket for AMD CPUs. Power supply: EVGA SuperNOVA 750 G5 80+ Gold 750W for stable and reliable power delivery. Case: Fractal Design Meshify C ATX Mid Tower for good airflow and ample room for components. This configuration provides a powerful and efficient system for running pre-trained language models like ChatGPT, and has been recommended by sources such as PC Gamer and Tom's Hardware.","Posted by u/Mr_DrProfPatrick - 9 votes and 34 comments"]}],"family_friendly":true}}